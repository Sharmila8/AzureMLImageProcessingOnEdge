{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/deployment/onnx/onnx-convert-aml-deploy-tinyyolo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Real-time Object Detection using ONNX on AzureML\n",
    "\n",
    "This example shows how to use the YOLO v3 model as a web service using Azure Machine Learning services and the ONNX Runtime.\n",
    "\n",
    "## What is ONNX\n",
    "ONNX is an open format for representing machine learning and deep learning models. ONNX enables open and interoperable AI by enabling data scientists and developers to use the tools of their choice without worrying about lock-in and flexibility to deploy to a variety of platforms. ONNX is developed and supported by a community of partners including Microsoft, Facebook, and Amazon. For more information, explore the [ONNX website](http://onnx.ai).\n",
    "\n",
    "## YOLO Details\n",
    "You Only Look Once (YOLO) is a state-of-the-art, real-time object detection system. For more information about YOLO, please visit the [YOLO website](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To make the best use of your time, make sure you have done the following:\n",
    "\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [configuration](../../../configuration.ipynb) notebook to:\n",
    "    * install the AML SDK\n",
    "    * create a workspace and its configuration file (config.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download YOLO v3 ONNX model \n",
    "\n",
    "First we download the model. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "onnx_model_url = \"https://onnxzoo.blob.core.windows.net/models/opset_10/yolov3/yolov3.onnx\"\n",
    "urllib.request.urlretrieve(onnx_model_url, filename=\"yolov3.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying as a web service with Azure ML\n",
    "\n",
    "### Load Azure ML workspace\n",
    "\n",
    "We begin by instantiating a workspace object from the existing workspace created earlier in the configuration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering your model with Azure ML\n",
    "\n",
    "Now we upload the model and register it in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"yolov3.onnx\",\n",
    "                       model_name = \"yolov3\",\n",
    "                       tags = {\"onnx\": \"yolov3\"},\n",
    "                       description = \"YOLOv3 from ONNX Model Zoo\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying your registered models\n",
    "\n",
    "You can optionally list out all the models that you have registered in this workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ws.models\n",
    "for name, m in models.items():\n",
    "    print(\"Name:\", name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write scoring file\n",
    "\n",
    "We are now going to deploy our ONNX model on Azure ML using the ONNX Runtime. We begin by writing a score.py file that will be invoked by the web service call. The `init()` function is called once when the container is started so we load the model using the ONNX Runtime into a global session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def init():\n",
    "    global session\n",
    "    model = Model.get_model_path(model_name = 'yolov3')\n",
    "    session = onnxruntime.InferenceSession(model)\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess(input_data_json):\n",
    "    # convert the JSON data into the tensor input    \n",
    "    imgb64 = json.loads(input_data_json)['data']    \n",
    "    \n",
    "    # Base64 decoding\n",
    "    image_64_decode = base64.b64decode(imgb64)\n",
    "    \n",
    "    # Open the image \n",
    "    img = Image.open(io.BytesIO(image_64_decode))\n",
    "    \n",
    "    \n",
    "    model_image_size = (416, 416)\n",
    "    \n",
    "    # Get the resized image\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    \n",
    "    # Normalize image\n",
    "    image_data /= 255.\n",
    "    \n",
    "     # Array has shape height x width x channel. We need to transpose it to channel x width x height            \n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    \n",
    "    # Add another dimension to make it an array of images    \n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    \n",
    "    image_size = np.array([img.size[1], img.size[0]], dtype=np.float32).reshape(1, 2)          \n",
    "    \n",
    "    return image_data, image_size\n",
    "\n",
    "def postprocess(result):\n",
    "    #r = np.array(result)\n",
    "    boxes = result[0]\n",
    "    scores = result[1]\n",
    "    indices = result[2]\n",
    "   \n",
    "    \n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    for idx_ in indices:\n",
    "        out_classes.append(idx_[1].tolist())\n",
    "        out_scores.append(scores[tuple(idx_)].tolist())\n",
    "        idx_1 = (idx_[0], idx_[2])\n",
    "        out_boxes.append(boxes[idx_1].tolist())    \n",
    "                   \n",
    "    er = {'boxes':out_boxes, 'scores':out_scores, 'classes':out_classes}\n",
    "\n",
    "    \n",
    "    return json.dumps(er)\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        image_data, image_size = preprocess(input_data_json)\n",
    "        \n",
    "        input_feeds = {}\n",
    "        input_feeds[session.get_inputs()[0].name] = image_data\n",
    "        input_feeds[session.get_inputs()[1].name] = image_size\n",
    "        \n",
    "        #input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
    "        result = session.run([], input_feeds)\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": postprocess(result),\n",
    "                \"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dependencies file\n",
    "Create a YAML file that specifies which dependencies we would like to see in our container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\",\"pillow\", \"onnxruntime\",\"azureml-defaults\", \"azureml-core\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as a local webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy as a local webservice\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "# Create inference configuration. This creates a docker image that contains the model.\n",
    "inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\")\n",
    "\n",
    "# Create a local deployment, using port 8890 for the web service endpoint\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "# Deploy the service\n",
    "service = Model.deploy(ws, \"mymodel\", [ws.models[\"yolov3\"]], inference_config, deployment_config)\n",
    "# Wait for the deployment to complete\n",
    "service.wait_for_deployment(True)\n",
    "# Display the port that the web service is available on\n",
    "print(service.port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the local webservice deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadLabels(labelsFile):\n",
    "    x = []\n",
    "    with open(labelsFile, 'r') as f:\n",
    "        x = f.readlines()    \n",
    "            \n",
    "    return x\n",
    "\n",
    "def drawBBoxesAndLabels(img, bsc, labels):\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    bcolor = 'red'\n",
    "\n",
    "    textfont = ImageFont.truetype(\"arial\", size=30)   \n",
    "    \n",
    "    for i in range(len(bsc[\"boxes\"])):\n",
    "        \n",
    "        y0 = int(bsc[\"boxes\"][i][0])\n",
    "        x0 = int(bsc[\"boxes\"][i][1])\n",
    "        y1 = int(bsc[\"boxes\"][i][2])\n",
    "        x1 = int(bsc[\"boxes\"][i][3])\n",
    "        \n",
    "        draw.rectangle(((x0,y0),(x1,y1)), outline=bcolor, width=5)\n",
    "        \n",
    "        #x0 = int((x0 + x1)/2)                \n",
    "        class_label = labels[bsc[\"classes\"][i]]\n",
    "        print(class_label)\n",
    "        text_size = textfont.getsize(class_label)\n",
    "        \n",
    "        draw.rectangle(((x0 - 10, y0 - 10),(x0 + text_size[0] + 10, y0 + text_size[1] + 10)), fill=\"black\")\n",
    "        \n",
    "        draw.text((x0,y0),class_label, fill = \"white\", font=textfont)\n",
    "        \n",
    "def plotImageWithBBoxesAndLabels(prediction, image_file):\n",
    "    r = json.loads(prediction)\n",
    "    \n",
    "    result = r[\"result\"]\n",
    "    \n",
    "    \n",
    "    bsc = json.loads(result)\n",
    "    #print(bsc)\n",
    "    \n",
    "    img = Image.open(image_file)\n",
    "    #img = Image.open(io.BytesIO(img_read))\n",
    "    print(img.size)\n",
    "    \n",
    "    labels = loadLabels(\"yolov3_classes.txt\")\n",
    "    \n",
    "    drawBBoxesAndLabels(img, bsc, labels)\n",
    "    \n",
    "    # Display the image\n",
    "    # Convert to numpy array\n",
    "    arr = np.asarray(img)    \n",
    "\n",
    "    # Display the image to make sure it has been downloaded and resized OK\n",
    "    plt.axis('off')\n",
    "\n",
    "    #fig = plt.figure(figsize=(1000, 1000))\n",
    "    #ax = fig.add_subplot(1, 1, 1)\n",
    "    #ax.imshow(arr)\n",
    "    \n",
    "    plt.imshow(arr)\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL  import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import urllib\n",
    "\n",
    "#image_url = \"https://i.ytimg.com/vi/SZ6PS_ADEcI/hqdefault.jpg\" \n",
    "#image_url = 'https://i.ytimg.com/vi/cjtLgiUQqgY/hqdefault.jpg'\n",
    "#image_url = \"https://leicesterhealth.files.wordpress.com/2012/03/cats_dogs_031.jpg\"\n",
    "#image_url = \"https://assets3.thrillist.com/v1/image/2799859/size/tmg-article_default_mobile.jpg\"\n",
    "image_url = 'https://i.imgur.com/BfO7BIr.jpg'\n",
    "\n",
    "\n",
    "downloaded_imagefile = \"image.jpg\"\n",
    "urllib.request.urlretrieve(image_url, downloaded_imagefile)\n",
    "\n",
    "#downloaded_imagefile = \"dog.jpg\"\n",
    "img = open(downloaded_imagefile, mode='rb') \n",
    "img_read = img.read() \n",
    "\n",
    "image_64_encode = base64.b64encode(img_read)\n",
    "\n",
    "\n",
    "###########\n",
    "# You cannot send a byte array in JSON and hence need to decode it to UTF-8\n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request and display the response\n",
    "    resp = requests.post(service.scoring_uri, input_data, headers=headers)    \n",
    "    #print(resp.text)\n",
    "    \n",
    "    \n",
    "    plotImageWithBBoxesAndLabels(resp.text, downloaded_imagefile)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the local webservice deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create container image in Azure ML\n",
    "Use Azure ML to create the container image. This step will likely take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  docker_file = \"Dockerfile\",\n",
    "                                                  description = \"YOLOv3 ONNX Demo\",\n",
    "                                                  tags = {\"demo\": \"yolov3\"}\n",
    "                                                 )\n",
    "\n",
    "\n",
    "image = ContainerImage.create(name = \"onnxyolov3\",\n",
    "                              models = [ws.models[\"yolov3\"]],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need to debug your code, the next line of code accesses the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're all set! Let's get our model chugging.\n",
    "\n",
    "### Deploy the container image as a webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = {'demo': 'yolov3'}, \n",
    "                                               description = 'web service for YOLO v3 ONNX model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will likely take a few minutes to run as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from random import randint\n",
    "\n",
    "aci_service_name = 'onnx-yolov3'+str(randint(0,100))\n",
    "print(\"Service\", aci_service_name)\n",
    "\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the deployment fails, you can check the logs. Make sure to delete your aci_service before trying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aci_service.state != 'Healthy':\n",
    "    # run this command for debugging.\n",
    "    print(aci_service.get_logs())\n",
    "    aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!\n",
    "\n",
    "If you've made it this far, you've deployed a working web service that does object detection using an ONNX model. You can get the URL for the webservice with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aci_service.scoring_uri)\n",
    "scoring_uri = aci_service.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL  import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import urllib.request\n",
    "\n",
    "#image_url = \"https://i.ytimg.com/vi/SZ6PS_ADEcI/hqdefault.jpg\" \n",
    "#image_url = 'https://i.ytimg.com/vi/cjtLgiUQqgY/hqdefault.jpg'\n",
    "#image_url = \"https://leicesterhealth.files.wordpress.com/2012/03/cats_dogs_031.jpg\"\n",
    "#image_url = \"https://assets3.thrillist.com/v1/image/2799859/size/tmg-article_default_mobile.jpg\"\n",
    "image_url = 'https://petcube.com/blog/content/images/2016/07/dogs-for-old-people-blog-cover-photo.jpg'\n",
    "#image_url = 'https://barkpost.com/wp-content/uploads/2015/04/elderly-people-with-dog.jpg'\n",
    "\n",
    "downloaded_imagefile = \"image.jpg\"\n",
    "urllib.request.urlretrieve(image_url, downloaded_imagefile)\n",
    "\n",
    "#downloaded_imagefile = \"dog.jpg\"\n",
    "img_file = open(downloaded_imagefile, mode='rb') \n",
    "img_read = img_file.read() \n",
    "\n",
    "image_64_encode = base64.b64encode(img_read)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# You cannot send a byte array in JSON and hence need to decode it to UTF-8\n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "scoring_uri = 'http://d37bf352-abe6-45d3-9ba8-4ab1fa6be417.westus2.azurecontainer.io/score'\n",
    "try:\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request and display the response\n",
    "    resp = requests.post(scoring_uri, input_data, headers=headers)    \n",
    "    #print(resp.text)\n",
    "    \n",
    "    \n",
    "    plotImageWithBBoxesAndLabels(resp.text, downloaded_imagefile)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are eventually done using the web service, remember to delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deprecate\n",
    "# Base64 decoding\n",
    "image_64_decode = base64.b64decode(image_64_encode)\n",
    "\n",
    "\n",
    "# Open the image \n",
    "img = Image.open(io.BytesIO(img_read))\n",
    "\n",
    "print(img.size)\n",
    "model_image_size = (416, 416)\n",
    "\n",
    "# Get the resized image\n",
    "boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "arr = np.asarray(boxed_image)\n",
    "print(arr.shape)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deprecate\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def init():\n",
    "    global session    \n",
    "    session = onnxruntime.InferenceSession(\"yolov3.onnx\", None)\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess(input_data_json):\n",
    "    # convert the JSON data into the tensor input    \n",
    "    imgb64 = json.loads(input_data_json)['data']    \n",
    "    \n",
    "    # Base64 decoding\n",
    "    image_64_decode = base64.b64decode(imgb64)\n",
    "    \n",
    "    # Open the image \n",
    "    img = Image.open(io.BytesIO(image_64_decode))\n",
    "    \n",
    "    \n",
    "    model_image_size = (416, 416)\n",
    "    \n",
    "    # Get the resized image\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    \n",
    "    # Normalize image\n",
    "    image_data /= 255.\n",
    "    \n",
    "     # Array has shape height x width x channel. We need to transpose it to channel x width x height            \n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    \n",
    "    \n",
    "    # Add another dimension to make it an array of images    \n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    \n",
    "    image_size = np.array([img.size[1], img.size[0]], dtype=np.float32).reshape(1, 2)          \n",
    "    \n",
    "    return image_data, image_size\n",
    "\n",
    "def postprocess(result):\n",
    "    print(result)\n",
    "    #r = np.array(result)\n",
    "    #print(r.shape)\n",
    "    boxes = result[0]\n",
    "    scores = result[1]\n",
    "    indices = result[2]\n",
    "   \n",
    "    \n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    for idx_ in indices:\n",
    "        out_classes.append(idx_[1].tolist())\n",
    "        out_scores.append(scores[tuple(idx_)].tolist())\n",
    "        idx_1 = (idx_[0], idx_[2])\n",
    "        out_boxes.append(boxes[idx_1].tolist())    \n",
    "                   \n",
    "    \n",
    "    er = {'boxes':out_boxes, 'scores':out_scores, 'classes':out_classes}\n",
    "\n",
    "    \n",
    "    return json.dumps(er)\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        image_data, image_size = preprocess(input_data_json)\n",
    "        \n",
    "        input_feeds = {}\n",
    "        input_feeds[session.get_inputs()[0].name] = image_data\n",
    "        input_feeds[session.get_inputs()[1].name] = image_size\n",
    "        \n",
    "        #input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
    "        result = session.run([], input_feeds)\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": postprocess(result),\n",
    "                \"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}\n",
    "    \n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "init()\n",
    "results = run(input_data)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "viswamy"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
