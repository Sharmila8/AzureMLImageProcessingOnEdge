{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/deployment/onnx/onnx-convert-aml-deploy-tinyyolo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Real-time Object Detection using ONNX on AzureML\n",
    "\n",
    "This example shows how to use the YOLO v3 model as a web service using Azure Machine Learning services and the ONNX Runtime.\n",
    "\n",
    "## What is ONNX\n",
    "ONNX is an open format for representing machine learning and deep learning models. ONNX enables open and interoperable AI by enabling data scientists and developers to use the tools of their choice without worrying about lock-in and flexibility to deploy to a variety of platforms. ONNX is developed and supported by a community of partners including Microsoft, Facebook, and Amazon. For more information, explore the [ONNX website](http://onnx.ai).\n",
    "\n",
    "## YOLO Details\n",
    "You Only Look Once (YOLO) is a state-of-the-art, real-time object detection system. For more information about YOLO, please visit the [YOLO website](https://pjreddie.com/darknet/yolo/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To make the best use of your time, make sure you have done the following:\n",
    "\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* Follow the instructions in the readme file before going through the steps in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download YOLO v3 ONNX model \n",
    "\n",
    "First we download the model. This may take a few minutes. The model will be downloaded to the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "onnx_model_url = \"https://onnxzoo.blob.core.windows.net/models/opset_10/yolov3/yolov3.onnx\"\n",
    "urllib.request.urlretrieve(onnx_model_url, filename=\"yolov3.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying as a web service with Azure ML\n",
    "\n",
    "### Load Azure ML workspace\n",
    "\n",
    "We begin by instantiating a workspace object from the existing workspace created in the configuration notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering your model with Azure ML\n",
    "\n",
    "Now we upload the model and register it in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path = \"yolov3.onnx\",\n",
    "                       model_name = \"yolov3\",\n",
    "                       tags = {\"onnx\": \"yolov3\"},\n",
    "                       description = \"YOLOv3 from ONNX Model Zoo\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying your registered models\n",
    "\n",
    "You can optionally list out all the models that you have registered in this workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ws.models\n",
    "for name, m in models.items():\n",
    "    print(\"Name:\", name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write scoring file\n",
    "\n",
    "We are now going to deploy our ONNX model on Azure ML using the ONNX Runtime. We begin by writing a score.py file that will be invoked by the web service call. The `init()` function is called once when the container is started so we load the model using the ONNX Runtime into a global session object. The `run()` function is called when the webservice is invoked for inferencing. After running the code below you should see a score.py file in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from azureml.core.model import Model\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def init():\n",
    "    global session\n",
    "    model = Model.get_model_path(model_name = 'yolov3')\n",
    "    session = onnxruntime.InferenceSession(model)\n",
    "\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess(input_data_json):\n",
    "    # convert the JSON data into the tensor input    \n",
    "    imgb64 = json.loads(input_data_json)['data']    \n",
    "    \n",
    "    # Base64 decoding\n",
    "    image_64_decode = base64.b64decode(imgb64)\n",
    "    \n",
    "    # Open the image \n",
    "    img = Image.open(io.BytesIO(image_64_decode))\n",
    "    \n",
    "    \n",
    "    model_image_size = (416, 416)\n",
    "    \n",
    "    # Get the resized image\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    \n",
    "    # Convert image to numpy array\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    \n",
    "    # Normalize image\n",
    "    image_data /= 255.\n",
    "    \n",
    "     # Array has shape height x width x channel. We need to transpose it to channel x width x height            \n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    \n",
    "    # Add another dimension to make it an array of images    \n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    \n",
    "    image_size = np.array([img.size[1], img.size[0]], dtype=np.float32).reshape(1, 2)          \n",
    "    \n",
    "    return image_data, image_size\n",
    "\n",
    "def postprocess(result):\n",
    "    #r = np.array(result)\n",
    "    boxes = result[0]\n",
    "    scores = result[1]\n",
    "    indices = result[2]\n",
    "   \n",
    "    \n",
    "    out_boxes, out_scores, out_classes = [], [], []\n",
    "    for idx_ in indices:\n",
    "        out_classes.append(idx_[1].tolist())\n",
    "        out_scores.append(scores[tuple(idx_)].tolist())\n",
    "        idx_1 = (idx_[0], idx_[2])\n",
    "        out_boxes.append(boxes[idx_1].tolist())    \n",
    "                   \n",
    "    er = {'boxes':out_boxes, 'scores':out_scores, 'classes':out_classes}\n",
    "\n",
    "    \n",
    "    return json.dumps(er)\n",
    "\n",
    "def run(input_data_json):\n",
    "    try:\n",
    "        start = time.time()   # start timer\n",
    "        image_data, image_size = preprocess(input_data_json)\n",
    "        \n",
    "        input_feeds = {}\n",
    "        input_feeds[session.get_inputs()[0].name] = image_data\n",
    "        input_feeds[session.get_inputs()[1].name] = image_size\n",
    "        \n",
    "        #input_name = session.get_inputs()[0].name  # get the id of the first input of the model   \n",
    "        result = session.run([], input_feeds)\n",
    "        end = time.time()     # stop timer\n",
    "        return {\"result\": postprocess(result),\n",
    "                \"time\": end - start}\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return {\"error\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dependencies file\n",
    "Create a YAML file that specifies which dependencies we would like to see in our container. After running the code below you should see myenv.yml in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=[\"numpy\",\"pillow\", \"onnxruntime\",\"azureml-defaults\", \"azureml-core\"])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy as a local webservice\n",
    "Before deploying as a webservice via Azure ML, lets deploy locally. This will take some minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deploy as a local webservice\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "# Create inference configuration. This creates a docker image that contains the model.\n",
    "inference_config = InferenceConfig(runtime=\"python\",\n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"myenv.yml\")\n",
    "\n",
    "# Create a local deployment, using port 8890 for the web service endpoint\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "# Deploy the service\n",
    "service = Model.deploy(ws, \"mymodel\", [ws.models[\"yolov3\"]], inference_config, deployment_config)\n",
    "# Wait for the deployment to complete\n",
    "service.wait_for_deployment(True)\n",
    "# Display the port that the web service is available on\n",
    "print(service.port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the local webservice deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Below are some helper functions\n",
    "\n",
    "# The file contains the labels for the 80 objects the YOLOv3 is trained for\n",
    "labelsFile = 'yolov3_classes.txt'\n",
    "\n",
    "def loadLabels(labelsFile):\n",
    "    x = []\n",
    "    with open(labelsFile, 'r') as f:\n",
    "        x = f.readlines()    \n",
    "            \n",
    "    return x\n",
    "\n",
    "def drawBBoxesAndLabels(img, bsc, labels):\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    bcolor = 'red'\n",
    "\n",
    "    textfont = ImageFont.truetype(\"arial\", size=20)   \n",
    "    \n",
    "    for i in range(len(bsc[\"boxes\"])):\n",
    "        \n",
    "        y0 = int(bsc[\"boxes\"][i][0])\n",
    "        x0 = int(bsc[\"boxes\"][i][1])\n",
    "        y1 = int(bsc[\"boxes\"][i][2])\n",
    "        x1 = int(bsc[\"boxes\"][i][3])\n",
    "        \n",
    "        # Draw the bounding boxes\n",
    "        draw.rectangle(((x0,y0),(x1,y1)), outline=bcolor, width=5)\n",
    "                \n",
    "        class_label = labels[bsc[\"classes\"][i]]\n",
    "        \n",
    "        text_size = textfont.getsize(class_label)\n",
    "        \n",
    "        # Draw the background rectangle for the label\n",
    "        draw.rectangle(((x0 - 10, y0 - 10),(x0 + text_size[0] + 10, y0 + text_size[1] + 10)), fill=\"black\")\n",
    "        \n",
    "        # Write the label\n",
    "        draw.text((x0,y0),class_label, fill = \"white\", font=textfont)\n",
    "        \n",
    "def plotImageWithBBoxesAndLabels(prediction, image_file):\n",
    "    r = json.loads(prediction)\n",
    "    \n",
    "    result = r[\"result\"]\n",
    "    \n",
    "    \n",
    "    bsc = json.loads(result)\n",
    "    #print(bsc)\n",
    "    \n",
    "    img = Image.open(image_file)        \n",
    "    \n",
    "    labels = loadLabels(labelsFile)\n",
    "    \n",
    "    drawBBoxesAndLabels(img, bsc, labels)\n",
    "    \n",
    "    # save the image\n",
    "    img.save(\"image_bboxes.jpg\")\n",
    "    \n",
    "    # Display the image\n",
    "    # Convert to numpy array\n",
    "    arr = np.asarray(img)    \n",
    "\n",
    "    # Display the image to make sure it has been downloaded and resized OK\n",
    "    plt.axis('off')   \n",
    "    plt.imshow(arr)\n",
    "    plt.show()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL  import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import urllib\n",
    "\n",
    "# Replace this with your own iamge URL. Use only RGB (not RGBA) images. Code will need to be updated to support RGBA images\n",
    "image_url = \"https://i.ytimg.com/vi/SZ6PS_ADEcI/hqdefault.jpg\" \n",
    "\n",
    "downloaded_imagefile = \"image.jpg\"\n",
    "# Download the image file\n",
    "urllib.request.urlretrieve(image_url, downloaded_imagefile)\n",
    "\n",
    "# Open the downloaded image file and read it in a buffer\n",
    "img = open(downloaded_imagefile, mode='rb') \n",
    "img_read = img.read() \n",
    "\n",
    "# Base 64 encoding\n",
    "image_64_encode = base64.b64encode(img_read)\n",
    "\n",
    "# You cannot send a byte array in JSON and hence need to decode it to UTF-8\n",
    "# This is the input data for the webservice\n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request\n",
    "    resp = requests.post(service.scoring_uri, input_data, headers=headers)    \n",
    "    #print(resp.text)\n",
    "    \n",
    "    # Display the image with the detected objects. Note the inline display will be small. Open the saved file to see it in full resolution\n",
    "    plotImageWithBBoxesAndLabels(resp.text, downloaded_imagefile)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the local webservice deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create container image in Azure ML\n",
    "Use Azure ML to create the container image. This step will likely take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(execution_script = \"score.py\",\n",
    "                                                  runtime = \"python\",\n",
    "                                                  conda_file = \"myenv.yml\",\n",
    "                                                  docker_file = \"Dockerfile\",\n",
    "                                                  description = \"YOLOv3 ONNX Demo\",\n",
    "                                                  tags = {\"demo\": \"yolov3\"}\n",
    "                                                 )\n",
    "\n",
    "\n",
    "image = ContainerImage.create(name = \"onnxyolov3\",\n",
    "                              models = [ws.models[\"yolov3\"]],\n",
    "                              image_config = image_config,\n",
    "                              workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you need to debug your code, the next line of code accesses the log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're all set! Let's get our model chugging.\n",
    "\n",
    "### Deploy the container image as a webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
    "                                               memory_gb = 4, \n",
    "                                               tags = {'demo': 'yolov3'}, \n",
    "                                               description = 'web service for YOLO v3 ONNX model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will likely take a few minutes to run as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from random import randint\n",
    "\n",
    "aci_service_name = 'onnx-yolov3'+str(randint(0,100))\n",
    "print(\"Service\", aci_service_name)\n",
    "\n",
    "aci_service = Webservice.deploy_from_image(deployment_config = aciconfig,\n",
    "                                           image = image,\n",
    "                                           name = aci_service_name,\n",
    "                                           workspace = ws)\n",
    "\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(aci_service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case the deployment fails, you can check the logs. Make sure to delete your aci_service before trying again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if aci_service.state != 'Healthy':\n",
    "    # run this command for debugging.\n",
    "    print(aci_service.get_logs())\n",
    "    aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!\n",
    "\n",
    "If you've made it this far, you've deployed a working web service that does object detection using an ONNX model. You can get the URL for the webservice with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aci_service.scoring_uri)\n",
    "scoring_uri = aci_service.scoring_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the webservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL  import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import base64\n",
    "import io\n",
    "import urllib.request\n",
    "\n",
    "image_url = \"https://i.ytimg.com/vi/SZ6PS_ADEcI/hqdefault.jpg\" \n",
    "\n",
    "\n",
    "downloaded_imagefile = \"image.jpg\"\n",
    "urllib.request.urlretrieve(image_url, downloaded_imagefile)\n",
    "\n",
    "\n",
    "img_file = open(downloaded_imagefile, mode='rb') \n",
    "img_read = img_file.read() \n",
    "\n",
    "image_64_encode = base64.b64encode(img_read)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# You cannot send a byte array in JSON and hence need to decode it to UTF-8\n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request and display the response\n",
    "    resp = requests.post(scoring_uri, input_data, headers=headers)    \n",
    "    \n",
    "    plotImageWithBBoxesAndLabels(resp.text, downloaded_imagefile)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are eventually done using the web service, remember to delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Azure IoT Edge device\n",
    "\n",
    "Follow [documentation](https://docs.microsoft.com/en-us/azure/iot-edge/quickstart-linux) to setup a Linux VM as an Azure IoT Edge device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy container to Azure IoT Edge device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.image import ContainerImage\n",
    "\n",
    "# Getting your container details\n",
    "container_reg = ws.get_details()[\"containerRegistry\"]\n",
    "reg_name=container_reg.split(\"/\")[-1]\n",
    "\n",
    "image = ws.images[\"onnxyolov3\"]\n",
    "    \n",
    "container_url = \"\\\"\" + image.image_location + \"\\\",\"\n",
    "subscription_id = ws.subscription_id\n",
    "print('{}'.format(image.image_location))\n",
    "print('{}'.format(reg_name))\n",
    "print('{}'.format(subscription_id))\n",
    "\n",
    "from azure.mgmt.containerregistry import ContainerRegistryManagementClient\n",
    "from azure.mgmt import containerregistry\n",
    "\n",
    "client = ContainerRegistryManagementClient(ws._auth,subscription_id)\n",
    "result= client.registries.list_credentials(ws.resource_group, reg_name, custom_headers=None, raw=False)\n",
    "\n",
    "username = result.username\n",
    "password = result.passwords[0].value\n",
    "\n",
    "print(username)\n",
    "print(password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a deployment.json file using the template json. Then push the deployment json file to the IoT Hub, which will then send it to the IoT Edge device. The IoT Edge agent will then pull the Docker images and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "module_name = \"yolov3\"\n",
    "\n",
    "file = open('iotedge-yolov3-template.json')\n",
    "contents = file.read()\n",
    "contents = contents.replace('__MODULE_NAME', module_name)\n",
    "contents = contents.replace('__REGISTRY_NAME', reg_name)\n",
    "contents = contents.replace('__REGISTRY_USER_NAME', username)\n",
    "contents = contents.replace('__REGISTRY_PASSWORD', password)\n",
    "contents = contents.replace('__REGISTRY_IMAGE_LOCATION', image.image_location)\n",
    "with open('./deployment.json', 'wt', encoding='utf-8') as output_file:\n",
    "    output_file.write(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter your the IoT device id and the IoT Hub name in the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push the deployment JSON to the IOT Hub\n",
    "!az iot edge set-modules --device-id <IoTdeviceid> --hub-name <IoTHubName> --content deployment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Before testing, open up inbound port 5001 on your Edge device. You can use [Azure Portal](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/nsg-quickstart-portal) for this purpose. \n",
    "Update the scoring URI with the edge device public IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "scoring_uri = 'http://<EdgeDeviceIPAddress>:5001/score'\n",
    "\n",
    "# You cannot send a byte array in JSON and hence need to decode it to UTF-8\n",
    "input_data = json.dumps({'data': image_64_encode.decode(\"utf-8\")})\n",
    "\n",
    "try:\n",
    "    \n",
    "    # Set the content type\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    # Make the request and display the response\n",
    "    resp = requests.post(scoring_uri, input_data, headers=headers)    \n",
    "    \n",
    "    plotImageWithBBoxesAndLabels(resp.text, downloaded_imagefile)\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "viswamy"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
